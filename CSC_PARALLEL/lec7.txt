	Лекция 7 (Модели памяти и проблемы видимости)

	1) Поиск ошибки с memory reordering:
Некоторая ошибка похожая на deadlock. Случается чаще
на серверных многоядерных машинах. Остальные потоки ждут
зависший и система перестает работать. Логирование так же
прекращается.

После подключения gdb или strace происходит spurious wakeups 
и система вновь работает.

* strace -p PID
	По аналогии с "gdb -p PID" подключаемся к сущ процессу
	еще один полезный способ анализа приложения

VFS (virtual file system) - дополнение к основной FS, не
существует реально на жестких дисках
	/dev - виртуальные файлы для устройств
	/sys
	/proc - вирт файлы для процессов (считываем не влияя
	на процесс, подглядываем)

C помощью "/proc/PID/stack" поняли, что поток висит на ф-ии
futex_wait(), но никто не уведомляет его. 
Т.е. этот поток что-то ожидает, но другие потоки так же 
ожидают его и не пытаются разбудить. 

Можем посмотреть стек потока и отследить сколько времени поток провел
на CPU и сделать вывод - стагнирует он или нет

Данная ошибка была обнаружена в ядре Linux.


	2) Общие сведения
Cache line in x86-64 = 64 bytes, регистры работают с кешом
а не памятью напрямую.

В кеш не может подгрузиться из памяти не 64 байта, т.е. если
мы запросили 8B то подгрузятся все 64В

Если в каком-то ядре уже в кеш-линии существуют эти данные,
то мы не полезем в память, а считаем из кеша соседнего ядра

Для таких случаев существуют протоколы поддержки когерентности
(согласованности) кешей процессоров


	3) Учебный протокол MESI работы ядер с кешами
Рассматриваем учебный протокол MESI, где каждая буква аббревиатуры
описывает состояние кеш-линии

LRU (list resently used) - выдавливаем из кеша последнюю наименее 
используемую кеш-линию в память (так происходит синхронизация кеш-линии
и памяти)

Брокер - посредник между памятью и кешом, который отвечает на запросы процессора
на конкретную память и высылает инструкции по решению данного запроса (читать из
памяти или из кеша другого CPU). Все обмены сообщениями для кеш линий 
CPU идут через брокер.

Если > 1 CPU одновременно произведут изменение ячейки памяти, то это все
равно будет согласованно брокером и ошибки не случится.

Состояние кеша процессора хранится в каждой линии кеша процессора (+ 2 bit):
	*I (invalidated)- кеш линия не используется
	*E (exclusive) 	- монопольное владение учатком памяти (нет у других ядер)
	не нужно ничего ни с кем согласовывать
	*S (shared) 	- когда > 1 CPU используют одну и туже ячейку памяти 
	(в таком случае брокер не говорит читать данные раз за разом из памяти, 
	а говорит считать из кеш-линии другого CPU)
	*M (modified) 	- линейка кеша переходит в это состояние, когда он находился
	в состоянии (E) и произошли изменения

Виды переходов состояний в MESI:
	1. I --> E (Всего 1-му CPU понадобился данный участок памяти)
	2. E --> M (Если модифифировали ячейку памяти, которая используется монопольно)
	3. E --> S (другой CPU запросил тот же участок памяти)
	4. S --> (E|M) (вытеснили линейку кеша процессора во всех CPU, кроме одного.
			   Происходит без синхронизации с памятью)
	5. M --> I (вытеснили линейку кеша на последнем CPU + произошла синхронизация)

Если мы находимся в состонии (S) и сделали изменение в кеш-линии, то мы посылаем 
брокеру сообщение о том, что другие ядра должны в нами синхронизироваться. После чего
ДОЖИДАЕМСЯ ПОДТВЕРЖЖДЕНИЯ ОТ ВСЕХ ЯДЕР и только после этого продолжаем свою работу.
Получаем своего рода блокировку.

Кеш нужен только для оптимизации, но при этом он прозрачен с точки срения логики.
Т.е. мы работаем, думая будто все процессоры обращаются в оперативную память каждый раз.


	4) Дополнение из реального мира к учебному примеру
В реальном мире добалено ещё 2 буффера для того, чтобы не дожидаться подтверждения
от всех ядер а продолжать дальше работать, это "store buffer"[1] and "invalidate queue"[2]

В "store buffer" мы скидываем кеш-линию после её модификации в состоянии (S), а в 
"invalidate queue" помещается запрос о том, что данную кеш линию нужно синхронизовать,
чтобы процессор делал это когда ему удобно и не сбивал свой налаженный конвеер (pipeline)

Подтвержение (invalidation acknowledgment сообщение) приходит тогда, когда запрос попадает 
в очередь, а не когда данная команда выполняется непосредственно на процессоре, 
т.е. все ядра обманывают нас :(


	5) Какие ошибки можем получить в соответствии с данной архитектурой
	* пример с memory reordering *
Данный memory reordering происходит не из-за компилятора (некоторых оптимизаций)
, когда он переставляем местами инструкции, а зависит только от реализации 
архитектруры. Т.е. НА ЭТАПЕ ИСПОЛНЕНИЯ железо сочло нужным действовать так.

Пример с запоздалой обработкой запроса (read/invalidate) во втором процессе.
Изначально только переменная "а" расшарена между th1 and th2. Т.е. "а" находится
в кеш линии в состоянии (S). А переменная "b" в кеш линии th1 в состоянии (E).
Изначально переменные инициализированы нулями (т.е. int a = b = 0).

-----------------------------------------------------
 cl(a) [S]	| cl(b)	[E]	| cl(a) [S]		|   --- 	| 
-----------------------------------------------------
 	th1					|	th2						|
------------------------|----------------------------
f() {					|	g() {					|
	a = 1;				|		while(b == 0)		|
	b = 1;				|		assert(a == 1)		|
}						|	}						|
-----------------------------------------------------
	* Поэтапное исполнение кода, приводящее к ошибке
1: a = 1 [th1]
	- кеш-линия с переменной "а" идет в "store buffer"
	- посылается сообщение "read/invalidate" другим ядрам
	// т.е. висит запрос на инвалидацию у th2, (считаем ackn уже пришел)
2: b == 0[th2]
	- посылается сообщение "read" брокеру сообщений
	- вынужденны ждать, пока не получим данные
	- в состояние (S) ещё не перешло, т.к. не получило ответа от брокера
3: b = 1 [th1]
	- линейка переходит в состояние (M) т.к. не приняло запрос от брокера
4: получаем запрос "read"
	- переменная "b" переходит в (S) на всех ядрах
5: переменная "b" приходит в кеш для th2 (b = 1)
6: выходим из цикла "while"
7: делается assert и фейлится, т.к. всё ещё не выполнился запрос из очереди.

	* Кратное объяснение этапов:
Может случиться такая ситуация, когда переменная 'a' находится
в состоянии (S), после модификации в th1 отправился запрос (read/invalidate)
для th2 (поместился в invalidate queue), но слишком поздно из этой очереди
обработался и у нас сфейлился assert

NOTES:
* Процессор не знает что в данном случае переменные 'a' и 'b' связаны между собой
логически.
* Если бы переменная 'a' не была в состоянии (S), то th2 вынужден был бы ждать,
чтобы получить эту переменную и такой ситуации не возникло.
* Или если бы запрос инвалидации отработал до 'assert', то такой ситуации так же
не было бы.

ВЫГОДА ИЗ ЭТОЙ АРХИТЕКТУРЫ:
В данном случае меняем согласованность на производительность, т.к. мы обрабатываем
запрос инвалидации когда нам удобно и не прерываем текущий сформированный конвеер 
комманд на несколько тактов вперед

Напоминает CAP теорему, но в нашем случае доступность преобладает над 
консистентностью

Если хотим максимальную производительность, то делаем так, чтобы память не 
пересекалась, тогда и кеши не будут пересекаться и не будет тратиться время
на согласование кешей

	* Схема данной "более реальной" архитектуры
read/invalidate отправляется брокеру после обновления
расшаренной кеш-линии

CPU0					CPU1
---------   			---------	
|line01	|read/invalidate|line11	|
|line02	|---> брокер    |line12	|
---------    --------	---------
   |	     |	    |	   |
store-buffer |      |	store-buffer
---------    --------	---------
|	    |	  |	   |	|		|
|line02	| <---|	   |	|		|
--------- ожидание |	---------
   |	  подтв.   |	   |
invalidate	  	   |	invalidate
queue		  	   |	queue
---------	  	   |	---------
|		|	  	   |-->	|line02	|
|		|    добавление	| 		|
---------    значений   ---------
             на инвалидацию

---------------------------------
|			RAM					| Синхронизация происходит
|								| благодаря LRU
---------------------------------


	6) Попытки все это детерминировать (memory bariers):
Существуют ассемблерные инстуркции которые позволяют:
	- реально дождаться подтверждения об запросе на инвалидацию
	  от других CPU
	- прервать текущий конвеер и честно выполнить все инвалидации
	  из очереди инвалидаций

В store buffer находятся все запросы, которые ожидают подтверждения на 
инвалидацию

	WRITE MEMORY BARIER "store buffer":
smp_wmb() - ожидает опустошения store-buffer (т.е. дожидается всех подтверждений
на инвалидацию)
Работает дольше rmb, т.к. ожидаем подтвержение от всех ядер

	READ MEMORY BARIER "invalidate queue":
smp_rmb() - принудительно выполняет все запросы на инвалидацию находящиеся в
invalidate queue
Работает быстрее wmb, т.к. выполняет свою очередь и все

smp_mb() - вызывает обе функции

	* Существует 4 вида теоретических барьеров памяти
Некоторое обобщение термина "барьер" для множества архитертур.
Теперь барьером мы называем не asm инструкцию, а такую пару слов
X,Y c {Store, Load}, говорящее слудующее:
	
Если установлен барьер X,Y то выполнять операцию Х перед
операцией Y

Впоследствии данный абстракции транслируются в конкретные 
ассемблерные комманды на конкретной архитектуре

	* Схема сущ. барьеров:
-------------------------------------
|load	1			|load	2		 |
|load 	(smp_rmb)	|store			 |
--------------------------------------
|store	3			|store	4		 |
|load				|store	(cmp_wmb)|
--------------------------------------

Все барьеры влияют на то в каком порядке мы реально увидим эти 
значения переменных

4 - все ЗАПИСИ до барьера, произойдут гарантированно раньше
всех записей после барьера

store1|
store2| 
...   | записи до барьера
storeN| (произойдут ранее)
----------------------
set StoreStore barier| ждем опустошения store-buffer-а
----------------------
store1'|
store2'| записи после барьера
...    | (произойдут позднее)
storeK'|
--------

Барьеры как примитивы синхронизации - должны работать согласованно
во всех местах. Т.е. если я ставлю барьер в одном месте, то я должен
поставить барьер и в другом месте

	7) Модели памяти:
Существуют некоторые платформы, которые гарантируют, что некоторые
виды барьеров нам ставить не нужно. Т.e. у некоторых процессоров
может отсутствовать "invalidate queue" (т.е. все переменные сразу, по честному
инвалидируются) или нет "store buffer"-а (т.е. сразу по честному ждем всех
подтверждений)

1, 2 - логически объединили в acquire (операции чтения до любых операций в секции)
2, 4 - логически объединили в release (операции записи  после любых операций в секции)

acquire - release semantics - некоторого рода логический захват и освобождение ресурса.
Данная пара не позволит никакому коду выйти за пределы секции между этими 2 барьерами.
 
.
.	[Load]
.
acuire (Load_{Load,Store})
	.
	. [Load before any]
	. [Store before load]
	.
release ({Load,Store}_Load)
.
. 	[Load before any]
.	[Load]
.	

	* sequential-consistensy 
		- применяются все барьеры после каждой операции
		- в данной архитектуре отсутствует "store buffer" ans "inv queue"
	* strong-ordered
		- все, кроме store-load. Бесплатная
		- acquire(1,2)-release(2,4) семантика при каждом чтении и каждой записи (x86)
	* weak-ordered 
		- нужно применять все барьеры самостоятельно (ARM)
	* super-weak 
		- чисто академический

Интересующие нас модели памяти: strong-ordered and weak-ordered

NOTE:
* В С++ ключевое слово volatile никак не относится к барьерам памяти (в отличии от java).
* В С++11 появились atomics и модели памяти в них появились в том числе. Когда используем
атомики по умолчанию применяются все барьеры памяти (будто работаем с моделью памяти:
sequential-consistensy). Но можно явно указывать какие барьеры памяти мы хотим применять.
* В С++ существуют только следующие модели для атомиков:
	- seq-cons
	- acquire
	- release
	- relaxes

