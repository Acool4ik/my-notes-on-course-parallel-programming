	Лекция №7 (Модели памяти и проблемы видимости)

	1) Поиск ошибки с memory reordering:
*strace -p
	по аналогии с gdb подключаемся к сущ процессу
	еще один полезный способ анализа приложения

VFS (virtual file system) - дополнение к основной FS, не
существует реально на жестких дисках
	/dev - виртуальные файлы для устройств
	/sys
	/proc - вирт файлы для процессов (считываем не влияя
	на процесс, подглядываем)
	
Можем посмотреть стек потока и отследить сколько времени поток провел
на CPU и сделать вывод - стагнирует он или нет

	2) Общие сведения
Cache line in x86-64 = 64 bytes, регистры работают с кешом
а не памятью напрямую

В кеш не может подгрузиться из памяти не 64 байта, т.е. если
мы запросили 8B то подгрузятся все 64

Если в каком-то ядре уже в кеш-линии существуют эти данные,
то мы не полезем в память, а считаем из кеша соседнего ядра

Для таких случаев существуют протоколы поддержки когерентности
(согласованности) кешей процессоров

	
	3) Учебный протокол работы ядер с кешами
Рассматриваем учебный протокол MESI, где каждая буква аббревиатуры
описываем состояние кеш-линии

LRU (list resently used) - выдавливаем из кеша последнюю наименее 
используемую кеш-линию в память (так происходит синхронизация кеш-линии
и памяти)

Брокер - посредник между памятью и кешом, который отвечает на запросы процессора
на конкретную память и высылает инструкции по решению данного запроса (читать из
памяти или из кеша другого CPU)

Состояние кеша процессора хранится в каждой линии кеша процессора (+ 2 bit)
	*I (invalidated) - кеш линия не используется
	*E (exclusive) - монопольное владение учатком памяти (нет у других ядер)
	не нужно ничего ни с кем согласовывать
	*S (shared) - когда > 1 кеш-линии в разных CPU используют одну и туже
	ячейку памяти (брокер не говорит читать данные из раза в раз из памяти, 
	а говорит считать из кеш линии другого CPU)
	*M (modified) - линейка кеша переходит в это состояние, когда он находился
	в состоянии (E) и произошли изменения

Если мы находимся в состонии (S) и сделали изменение в кеш-линии, то мы посылаем 
брокеру сообщение о том, что другие ядра должны в нами синхронизироваться. После чего
дожидаемся подтверждения от ВСЕХ ЯДЕР и только после этого продолжаем свою работу.
Получаем своего рода блокировку.

Кеш нужен только для оптимизации, но при этом он прозрачен с точки срения логики.
Т.е. мы работаем, думая будто все процессоры обращаются в оперативную память каждый раз.


	4) Дополнение из реального мира к учебному примеру
В реальном мире добалено ещё 2 буффера для того, чтобы не дожидаться подтверждения
от всех ядер а продолжать дальше работать, это store buffer[1] and invalidate queue[2]

В store buffer мы скидываем кеш линию после её модификации в состоянии (S), а в 
invalidate queue помещается запрос о том, что данную кеш линию нужно синхронизовать,
чтобы процессор делал это когда ему удобно и не сбивал свой налаженный конвеер

Подтвержение приходит тогда, когда запрос попадает в очередь, а не когда данная команда
выполняется непосредственно на процессоре, т.е. все ядра обманывают нас :(


	5) Какие ошибки можем получить в соответствии с данной архитектурой
	* пример с memory reordering *
Данный memory reordering происходит не из-за компилятора (некоторых оптимизаций)
, когда он переставляем местами инструкции, а зависит только от реализации 
архитектруры. Т.е. на этапе исполнения железо сочло нужным действовать так.

Пример с запоздалой обработкой запроса (read/invalidate) во втором процессе
Изначально все 2 переменный разшарены между th1 and th2 и инициализированы нулями.

 	th1		|	th2
------------------------|-----------------------------
f() {			|	g() {
	int a = 1;	|		while(b == 0)
	int b = 1;	|		assert(a == 1)
}			|	}
------------------------------------------------------

Может случиться такая ситуация, когда переменная 'a' находится
в состоянии (S), после модификации в th1 отправился запрос (read/invalidate)
для th2 (поместился в invalidate queue), но слишком поздно из этой очереди
обработался и у нас сфейлился assert

Процессор не знает что в данном случае переменные 'a' и 'b' связаны между собой
логически.

ВАЖНОЕ ЗАМЕЧАНИЕ:
Если бы переменная 'a' не была в состоянии (S), то th2 вынужден был бы ждать,
чтобы получить эту переменную и такой ситуации не возникло.

Или если бы запрос инвалидации отработал до 'assert', то такой ситуации так же
не было бы.

ВЫГОДА ИЗ ЭТОЙ АРХИТЕКТУРЫ:
В данном случае меняем согласованность на производительность, т.к. мы обрабатываем
запрос инвалидации когда нам удобно и не прерываем текущий сформированный конвеер 
комманд на несколько тактов вперед

Напоминает CAP теорему, но в нашем случае доступность преобладает над 
консистентностью

Если хотим максимальную производительность, то делаем так, чтобы память не 
пересекалась, тогда и кеши не будут пересекаться

	Схема данной более 'реальной' архитектуры
read/invalidate отправляется брокеру после обновления
расшаренной кеш-линии

CPU0			CPU1
---------  read/	---------	
|line01	|  invalidate	|line11	|
|line02	|-->  брокер    |line12	|
---------    --------	---------
   |	     |	    |	   |
store-buffer |      |	store-buffer
---------    --------	---------
|	|     |	   |	|	|
|line02	| <---|	   |	|	|
--------- ожидание |	---------
   |	  подтв.   |	   |
invalidate	   |	invalidate
queue		   |	queue
---------	   |	---------
|	|	   |-->	|line02	|
|	|    добавление	| 	|
---------    значений   ---------
             на инвалидацию

---------------------------------
|	RAM			|
|				|
---------------------------------

	6) Попытки все это детерминировать (memory bariers):
Существуют ассемблерные инстуркции которые позволяют:
	- реально дождаться подтверждения об запросе на инвалидацию
	  от других CPU
	- прервать текущий конвеер и честно выполнить все инвалидации
	  из очереди инвалидаций

В store buffer находятся все запросы, которые ожидают подтверждения на 
инвалидацию

	WRITE MEMORY BARIER:
smp_wmb() - ожидает опустошения store-buffer (т.е. дожидается всех подтверждений
на инвалидацию)
Работает дольше rmb, т.к. ожидаем подтвержение от всех ядер

	READ MEMORY BARIER:
smp_rmb() - принудительно выполняет все запросы на инвалидацию находящиеся в
invalidate queue
Работает быстрее wmb, т.к. выполняет свою очередь и все

smp_mb() - вызывает обе функции

	Существует 4 вида теоретических барьеров памяти
Впоследствии транслируются в ассемблерные комманды на 
конкретной архитектуре

---------------------------------
|load	1	|load	2	|
|load		|store		|
---------------------------------
|store	3	|store	4	|
|load		|stre		|
---------------------------------

Все барьеры влияют на то в каком порядке мы реально увидим эти 
значения переменных

4 - все ЗАПИСИ до барьера, произойдут гарантированно раньше
всех записей после барьера

store1|
store2| 
...   | записи до берьера
storeN| (произойдут ранее)
------------------
StoreStore barier| ждем опустошения store-buffer-а
------------------
store1'|
store2'| записи после барьера
...    | (произойдут позднее)
storeK'|
--------

Барьеры как примитивы синхронизации - должны работать согласованно
во всех местах. Т.е. если я ставлю барьер в одном месте, то я должен
поставить барьер и в другом месте

	7) Модели памяти:
Существуют некоторые платформы, которые гарантируют, что некоторые
виды барьеров нам ставить не нужно. Т.e. у некоторых процессоров
может отсутствовать invalidate queue (т.е. все переменные сразу, по честному
инвалидируются) или нет store-buffer-а (т.е. сразу по честному ждем всех
подтверждений)

1, 2 - логически объединили в acquire (операции чтения до любых операций в секции)
2, 4 - логически объединили в release (операции записи  после любых операций в секции)

acquire - release semantics - некоторого рода логический захват и освобождение ресурса.
Данная пара не позволит никакому коду выйти за пределы секции между этими 2 барьерами.

	* sequential-consistensy 
		- применяются все барьеры после каждой операции
	* strong-ordered 
		- все, кроме store-load. Бесплатная
		- acqure-release семантика при каждом чтении и каждой записи (x86)
	* weak-ordered 
		- нужно применять все барьеры самостоятельно (ARM)
	* super-weak 
		- чисто академический

Интересующие нас модели памяти: strong-ordered and weak-ordered

В С++ ключевое слово volatile никак не относится к барьерам памяти (в отличии от java).

В С++11 появились atomics и модели памяти в них появились в том числе. Когда используем
атомики по умолчанию применяются все барьеры памяти (будто работаем с моделью памяти:
sequential-consistensy). Но можно явно указывать какие барьеры памяти мы хотим применять.

В С++ существуют только следующие модели для атомиков:
	- seq-cons
	- acqure
	- release
	- relaxes

