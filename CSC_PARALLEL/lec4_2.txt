	Lecture 4 (part 2, algorighms sychronizations)

#1) Оптимистичная синхронизация
    * в отличие от тонкой синхронизации лочим только 
      те элементы которые нужны
    ПРОВЕРКИ:
    - проверяем что элементы по-прежнему в списке
      проходя ещё раз по списку
    - проверяем что эл-ты по-прежнему соседние
    ИТОГО:
    - если хотя бы 1 условие не выполняется - повторяем
      алгоритм заново

NOTE: позволяет улучшить производительность системы в целом
а не отдельных потоков
ПРЕИМУЩЕСТВО: потоки друг с другом не "сталкиваются", но 
требуем больше процессорного времени (жертвуем процессорным временем)

NOTE: удаление корректно обрабатывается на языках со сборщиком
мусора

----    -----
|  | -->|   | // в этом случае все равно получится корректно работает
----    ----- // но ссылку у удаленного эл-та нужно занулять
----  _/
|  |-/    удаленный элемент
----
При таком подходе большее число потоков могут || получать доступ
к структуре -> общая производительность системы растет


#2) Ленивая синхронизация
* На чтение данные используются намного чаще. Значит
оптимизируем операцию поиска.

* Помечаем просто "галочкой" что элемент был удален и оставляем
его висеть в памяти. (при снижении пиковой нагрузки удаляем)

* Больше не требуется проходить по списки ещё один раз. Достаточно
проверить 2 флага и что элементы соседние.

* Поиск производится всегда по "ключу"

* Для адресации в 64-битной архитектуре в адресе используется 48 бит

NOTE: поиск при таком подходе wait-free. Т.е. мы гарантированно за O(n)
выдаем результат (точнее за 1 проход)


#3) неблокирующие алгоритмы (lock-free)

----    -----
|3 | -->|5  | 
----    -----
        /  // создаем ссылку на следующий эл-т
----  _/
|4 |-/   // наш новосозданный эл-т
----
NOTE: с помощью CAS стараемся так же установить ссылку с предыдущего
на текущий эл-т, итого получаем:

----    -----
|3 |    |5  | 
----    -----
 |      /
----  _/
|4 |-/  
----
	Некоторые выводы:
* отсутствуют примитивы синхронизации (но сущ CAS), это гарантирует что
ни одни потоки не влияют на другие потоки

* если в ЛЮБОЙ момент времени мы остановим К потоков из N, то оставшиеся
(N-K) потоков гарантированно доделают свою работу

* если даже CAS возвращает false то мы знаем, что другому потоку
удалось сделать свою задачу и система в целом прогрессирует

* см алгоритм снятия snapshop-ов атомарных регистров


#4) wait-free алгоритмы
Более жесткий класс алгоритмов, с большими ограничениями

Если мы остановим K потоков из N в произвольный момент времени, то 
оставшиеся (N - K) потоков не просто когда-то завершат свои задачи,
а сделают это не более чем за M загов, M != f(число потоков), 
зависит только от размера структуры данных.
// допустим CAS не сработает не более чем 5 раз у каждого

NOTE: обычно структуры не полностью lock-free или wait-free а лишь
отдельные операции над структурой
// Поиск wait-free в нашем примере, т.к. за N шагов он гарантированно
заканчивается


	Как использовать CAS со структурами > машинного слова?
Импользуем указатели на эти структуры (приходится полагаться, что
структура иммутабельная)

	Снятие snapshot-ов атомарных регистров
SWMR (single wrine multiple readers) - важно только для wait-free,
у нас lock-free алгоритм, нам это ограничение не важно

 th1     th2      // only write in yourself registers
------  ------    Lock-free snapshots
| 0  |  | 0  |		((0, 0), (0, 0))
| 0  |  | 0  |		
-----   ------
Инкрементируем версию при записи

 th1     th2   		((x1, v1), (x2, v2))
------  ------	        
| 2  |  | 0  |		((0, 0), (0, 0))
| 1  |  | 0  |		((2, 1), (0, 0))	
-----   ------

NOTE: если версии у i-го и (i+1)-го snapshot-а совпадают, то никто
кроме нас гарантированно ничего в регистр не писал

в printf внутри воддерживается атомарный вывод!

